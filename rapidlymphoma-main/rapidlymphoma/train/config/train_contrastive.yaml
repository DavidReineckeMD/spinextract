infra:
    log_dir: ./ # where all the experiments are
    exp_name: rapid_lymhoma # create a subdirectory for each set of experiments
    comment: dev # can use this to customize for each experiment
    seed: 1000
data:
    db_root: /path/to/data/ 
    balance_patch_per_class: true
    train_augmentation:
    - which: random_horiz_flip
      params: {}
    - which: random_vert_flip
      params: {}
    - which: gaussian_noise
      params: {}
    - which: color_jitter
      params: {}
    - which: random_autocontrast
      params: {}
    - which: random_solarize
      params:
        threshold: 0.2
    - which: random_sharpness
      params:
        sharpness_factor: 2
    - which: gaussian_blur
      params:
        kernel_size: 5
        sigma: 1
    - which: random_affine
      params:
        degrees: 10
        translate: [0.1, 0.3]
    - which: random_resized_crop
      params:
        size: 300
    - which: random_erasing
      params: {}
    valid_augmentation:
    - which: random_horiz_flip
      params: {}
    - which: random_vert_flip
      params: {}
    - which: gaussian_noise
      params: {}
    - which: color_jitter
      params: {}
    - which: random_autocontrast
      params: {}
    - which: random_solarize
      params:
        threshold: 0.2
    - which: random_sharpness
      params:
        sharpness_factor: 2
    - which: gaussian_blur
      params:
        kernel_size: 5
        sigma: 1
    - which: random_affine
      params:
        degrees: 10
        translate: [0.1, 0.3]
    - which: random_resized_crop
      params:
        size: 300
    - which: random_erasing
      params: {}
    rand_aug_prob: 0.3
model:
    backbone: resnet50
    mlp_hidden: []
    num_embedding_out: 128
training:
    objective: byol
    batch_size: 128
    num_epochs: 270
    optimizer: adamw # [sgd, adam, adamw]
    learn_rate: 1.0e-3
    scheduler:
        which: cos_warmup
        params:
            num_warmup_steps: 0.1
            num_cycles: 0.5
    imagenet_backbone_checkpoint: null
